* The Quipu Data Structure

The [[http://en.wikipedia.org/wiki/Rope_%28data_structure%2][rope]] data structure has an interesting quality: it could be implemented
such that the structure of the rope is the same as the structure of the
abstract syntax tree.

The rope itself is efficient and works well for text editing. Combining ropes
with semantics we call a quipu.

** Prerequisites

A good parser. [[https://github.com/UpstandingHackers/hammer][Hammer]] is the leading candidate. A binary focus may be turned
and tuned to utf-8, going the other direction is painful. The parser will
be capable of outputting several data structures, the quipu form among them,
offset tables being the other major flavor.

The parser must have a good [[file:parse-repair.org][parse repair strategy]]. Keeping things tree-like
is critical to performance. Although we can and will fall back on the basic
rope for flat sections, this isn't acceptable for the larger application,
which is a ground-up, semantically-aware library of editing functions.

** Structure

A rope node contains the length and pointers to the left and right.

A quipu adds an enriched node type, that has semantics and is n-ary.

We balance the quipu by inserting additional, ordinary-rope-like
nodes, which we call pivots.

We end up  with a binary tree,  used for editing, braided  with an n-ary
tree, used  for semantic purposes. The  DAG has the properties  of being
well-formed (single root node) and convergent (both the n-ary and binary
DAGs contain the same leaf nodes, reached by different paths).

** Use

Superficially, it works similarly to a rope. But to stay semantically in sync,
it has to cooperate with the parser, and this can be a disaster if not carefully
implemented.

Parsing is an all-or-nothing proposition, normally: a string is correct right up
until it isn't, and then it's all wrong. Even regex scans that approximate a parse,
like syntax highlighting, gets tripped up by this: delete the " at the end of a
string in a code editor to see what I mean. I suspect you already have.

Fortunately for all of us, [[http://www.antlr.org/][ANTLR]] has an incredible parse repair algorithm. I've
mentioned it a few times in notes and really need to crack open the PDF and
transcribe it, because it really impressed me and it can be adapted to PEGs.
The reference is section 9.3 of the manual.

As I said, you need a really good parser. But with that parser, and a quipu,
one can write a really tight editing library on top.

That is a topic for another page.

** Problems

Ropes like to be binary and balanced. Parse trees are either n-ary and fairly
well balanced, or binary and strongly tail-loaded.

I suspect one could get acceptable balance by forcing a left-right structure onto
n-ary nodes. These pivot nodes would be anonymous so ((foo)(bar)(baz)), which
we'd often parse

- cons
  - head :: "foo""
  - tail :: cons
    - head :: "bar"
    - tail :: cons
      - head :: "baz"

We could instead parse

- list
 - head :: pivot
   - head :: pivot
      - head :: "foo"
      - tail :: ""bar""
   - tail :: pivot
      - head :: "baz"

Leaving out a level of detail to make the picture more clear.

We can see with this small example that it's not growing left. A typical long parse,
intuitively, will end up balanced with this approach. Balanced enough.

Also worth remembering: We're doing semantic editing with this library. It will,
almost by definition, have poorer algorithmic characteristics than a structure-unaware
string of some sort, such as a skip-list rope.

However, we were going to do semantic analysis on that string anyway. Normally this is a
regular expression driven parse over at least the region under display, with periodic
full reparses by the language runtime. We can't normally eliminate the latter, at least
not at first, but the point of a quipu is to perform that semantic analysis and then preserve
it through various transformations, nearly all of which put the parse tree in a temporary
state of error.

We can also rebalance off the pivots, by flipping them on and off in various ways. The pivots
don't affect the semantics of the tree, just the shape, they don't have to be added in
consistent ways, we can attempt to pivot in the balancing direction each time.

*** Digging in


The basic strategy has two types of node.

The initial parse creates semantic nodes, which are n-ary and link
together. Semantic nodes that aren't unary or binary contain an
additional two slots.

The  balance  pass  assigns  a  left-right chain  through  each  of  the
subnodes. The pointers for the first two subnodes go into left and right
respectively and are distributed among the subnodes accordingly.

Since we know the bias of the nodes, which are aware of their span,
we can correct for it with our pivot placement.

We now have a quipu, with nodes, some of which are fat, and pivots, which
give our tree a balanced shape.

We can save these to store by translating the pointers into offsets and compressing the
node structure into a header. This can be laid out in a cache-friendly way,

The tendency of structured data is to stay structured, and our parser will be
designed to enforce this.

Since our pivots are anonymous, we can break any long flat
data up into ordinary ropes.

*** Picture

Here's a lisp tree:

#+begin_src emacs-lisp :exports code
  (defun foo (eeny meeny)
      "a foo function"
      if (eq eeny meeny )
      (miney moe)
      (fi fie fo fum))
#+end_src

Let's render the AST:

#+BEGIN_SRC dot :file images/node-leaf.png  :exports results :cache yes
   digraph G {
  list [label = "list", style = filled, fillcolor = cyan]

  node_1 [label = "defun", style = filled, fillcolor = gray]
  foo_node [label = "foo", style = filled, fillcolor = gray]
  list_1 [label = "list 1", style = filled, fillcolor = cyan]
  node_4 [label = "\"a foo function\"", style = filled, fillcolor = gray]
  list_2 [label = "list 2", style = filled, fillcolor = cyan]
  node_5 [label = "if", style = filled, fillcolor = gray]
  list_3 [label = "list 3", style = filled, fillcolor = cyan]
  list_4 [label = "list 4", style = filled, fillcolor = cyan]
  node_2 [label = "eeny", style = filled, fillcolor = gray]
  node_3 [label = "meeny", style = filled, fillcolor = gray]
  list_5 [label = "list 5", style = filled, fillcolor = cyan]
  list_6 [label = "list 5", style = filled, fillcolor = cyan]
  node_6 [label = "eq", style = filled, fillcolor = gray]
  node_7 [label = "eeny", style = filled, fillcolor = gray]
  node_8 [label = "meeny", style = filled, fillcolor = gray]
  node_9 [label = "miney", style = filled, fillcolor = gray]
  node_10 [label = "mo", style = filled, fillcolor = gray]
  node_11 [label = "fi", style = filled, fillcolor = gray]
  node_12 [label = "fie", style = filled, fillcolor = gray]
  node_13 [label = "fo", style = filled, fillcolor = gray]
  node_14 [label = "fum", style = filled, fillcolor = gray]
    list -> node_1
    list -> foo_node
     list -> list_1
     list_1 -> node_2
     list_1 -> node_3
     list -> node_4
     list -> list_2
     list_2 -> node_5
     list_2 -> list_3
     list_3 -> list_4
     list_4 -> node_6
     list_4 -> node_7
     list_4 -> node_8
     list_3 -> list_5
     list_5 -> node_9
     list_5 -> node_10
     list_3 -> list_6
     list_6 -> node_11
     list_6 -> node_12
     list_6 -> node_13
     list_6 -> node_14
  }

#+END_SRC

#+RESULTS[a717a90928e0c199fb262837a042001b8f1059c4]:
[[file:images/node-leaf.png]]

I made it fairly balanced.

Now let's painstakingly add some pivots.


#+begin_src dot :file images/node-pivot-leaf.png  :exports results :cache yes
   digraph G {
  list [label = "list", style = filled, fillcolor = cyan]
  pivot_1 [label = "pivot", style = filled, fillcolor = green]
  node_1 [label = "defun", style = filled, fillcolor = gray]
  foo_node [label = "foo", style = filled, fillcolor = gray]
  pivot_2 [label = "pivot", style = filled, fillcolor = green]
  list_1 [label = "list 1", style = filled, fillcolor = cyan]
  pivot_3 [label = "pivot", style = filled, fillcolor = green]
  node_4 [label = "\"a foo function\"", style = filled, fillcolor = gray]
  list_2 [label = "list 2", style = filled, fillcolor = cyan]
  node_5 [label = "if", style = filled, fillcolor = gray]
  list_3 [label = "list 3", style = filled, fillcolor = cyan]
  list_4 [label = "list 4", style = filled, fillcolor = cyan]
  node_2 [label = "eeny", style = filled, fillcolor = gray]
  node_3 [label = "meeny", style = filled, fillcolor = gray]
  list_5 [label = "list 5", style = filled, fillcolor = cyan]
  list_6 [label = "list 6", style = filled, fillcolor = cyan]
   pivot_5 [label = "pivot", style = filled, fillcolor = green]
  node_6 [label = "eq", style = filled, fillcolor = gray]

  node_7 [label = "eeny", style = filled, fillcolor = gray]
  node_8 [label = "meeny", style = filled, fillcolor = gray]
  node_9 [label = "miney", style = filled, fillcolor = gray]
  node_10 [label = "mo", style = filled, fillcolor = gray]
  pivot_6 [label = "pivot", style = filled, fillcolor = green]
  node_11 [label = "fum", style = filled, fillcolor = gray]
  node_12 [label = "fo", style = filled, fillcolor = gray]
  node_13 [label = "fi", style = filled, fillcolor = gray]
  node_14 [label = "fie", style = filled, fillcolor = gray]
  pivot_7 [label = "pivot", style = filled, fillcolor = green]
  pivot_8 [label = "pivot", style = filled, fillcolor = green]

    list -> pivot_1 [color = red]
    list -> node_1
    list -> foo_node
       pivot_1 -> node_1 [color = red]
       pivot_1 -> foo_node [color = red]
    list -> pivot_2 [color = red]
     pivot_2 -> list_1 [color = red]
     list -> list_1
     list_1 -> node_2  [color = red]
     list_1 -> node_3   [color = red]
     pivot_2 -> pivot_3 [color = red]
     pivot_3 -> node_4  [color = red]
     pivot_3 -> list_2  [color = red]
     list -> node_4
     list -> list_2
     list_2 -> node_5    [color = red]
     list_2 -> list_3   [color = red]
     list_3 -> list_4   [color = red]
     list_4 -> node_6   [color = red]
     list_4 -> node_7
     list_4 -> node_8
     list_4 -> pivot_5   [color = red]
     pivot_5 -> node_7   [color = red]
     pivot_5 -> node_8   [color = red]
     list_3 -> list_5
     list_3 -> pivot_6    [color = red]
     pivot_6 -> list_5    [color = red]
     pivot_6 -> list_6    [color = red]
     list_5 -> node_9    [color = red]
     list_5 -> node_10   [color = red]
     list_3 -> list_6
     list_6 -> node_11
     list_6 -> node_12
     list_6 -> pivot_7      [color = red]
     pivot_7 -> node_11     [color = red]
     pivot_7 -> node_12     [color = red]
     list_6 -> pivot_8      [color = red]
     list_6 -> node_13
     list_6 -> node_14



     pivot_8 -> node_13     [color = red]
     pivot_8 -> node_14     [color = red]
  }
#+end_src

#+RESULTS[e3757a81acd6d8009b3ec5aac1911875fb11a583]:
[[file:images/node-pivot-leaf.png]]

And that's a quipu. Parens and whitespace elided, they don't really help.

There are places to make this more balanced, like pivoting between list 4
and 5 instead of 5 and 6.

**** DONE Get dot working with Org
     CLOSED: [2015-03-17 Tue 22:19]

** Algorithmic Properties.

I believe the quipu inherits the properties of a rope for ordinary operations.
To be fair, it can't be tuned to maintain a fully optimal structure, by choosing
a string length that complements the cache, balancing the tree with only speed
in mind, and so on.

But again, we use a quipu when we were going to have an AST anyway. This
gap-buffer plus a grip of regex nonsense has to stop.

Note that nodes are also pivots, so in a quipu 'node' refers specifically to
the n-ary structure with attached semantics. pivot refers to both.

Let's call *n*  the number of nodes,  *p* the number of  pivots, and *c*
the number of characters in the string. n < p < c, the first a subcategory
of the second.

The rope is known to hang out around gap buffers and skip lists for baseline
performance, with qualities that suit it to immutable edits.

The quipu inherits this, with other interesting properties.

=mark-region= is O(?), where ? is the number of nodes between master and the
region to be highlighted. This is true of any similar functions, such as
code folding or most colorizing. What's the average here, n log n?

Operations such as seach-and-replace  or autocomplete become faster when
restricted to semantic categories. We  can completely skip any subregion
that won't have our information.

Consider a literate document, split into presentation and code. From
the perspective of our environment, they may as well be completely
separate: each boundary is visited once and declined immediately.

A common situation is to have a string which is interpolated with other data
along semantic boundaries. The *ML family of markup languages are useful
to work with in this fashion. The object pointer in the node structures
allows us to abstract away this situation, and render it flexibly, with
good performance.

The goal is to combine the time characteristics of a rope and an AST
for their characteristic problem domains, with a modest, O(p-n) increase in memory
requirements over a perfectly flat string indexed by an AST.

We can probably make  it smaller than a rope indexed by  an AST. We also
avoid the inevitable  complexity of applying a  tree-like structure over
another tree-like structure, which may well be discontiguous in memory.

*** Cache Awareness

Though by no means the first thing to add, implementation should proceed with
an eye towards cache-friendly layout.

I could use a lot of help. I know the basics but have in fact never
written code with hard performance requirements like we're talking about here.

I learned the craft on a 286 with 640k OK and have miserly instincts, so
I do care.

I know we want chunks to be large enough that they flow through a pipeline,
but small enough that if we hand them off to garbage collectors they won't get
tagged as enormous and impossible to move.

The basic strategy is to write into blocks allocated from some pool, packing the
pivots into the front and the strings into the back. The strings should have
telomeres on both sides, zeroes we can consume with additions, and should be in
order, so we can strip the strings by pulling off the footers and filtering nulls.

I haven't the faintest idea how to move the contents around as the quipu are
juggled. BTW the zeroes in the telomeres are junk, not semantics, the quipu
preserves the length of data. It's safe to stuff zeroes in there, as long
as you're willing to strip the data back out using the quipu rather than
footer filtering.

I want this to be fast enough that it would be worth writing a filesystem
over it. That's not what I want it for, but it would make the application
in question better.

** Immutability

It's worthwhile having a version of this that's designed for immutable revision.

My head starts to swell when I have to think about immutable data structures,
especially when thread-safe references are going to be in the picture. Add this to
the cache picture and we're well outside my comfort zone.

I do know that the zipper has much wisdom to provide.

The basic strategy is to add one more pointer to semantic nodes. Any change that affects
a node is recorded as a back reference, and the node affected gets a pointer stuffed
onto a stack. That's your global undo. Regional undo follows the back reference
and must remove that change from the stack.

I'm pretty sure the old state is cloned and put in the past, so that a give node
retains the same literal identity. At least for our purposes. This makes it slow,
but possible, to access old trees. We have revision control for that purpose,
and are more interested in undos than working with the full state of old data.

** Integration

A string library isn't particularly useful on its own. Strings are the
classic case for garbage collection, and we want the quipu to be
usable from dynamic languages.

Lua lets us use [[http://stackoverflow.com/questions/3578401/lua-garbage-collection-userdata][lua_newuserdata()]] in place of malloc(), allowing the GC
to handle reference counting directly. We'll want to make malloc() and
free() into macros, since I'm sure most GC languages with a good FFI
provide an equivalent function.

This is simplistic, there are many questions to answer, but we're past
the point where continuing to specify is practical. Bottom line, it's a
DAG, and DAGs have been allocated and freed before.
** Implementation

I'd rather write and profile the data structure in LuaJIT,
then see if there's anything left to optimize. That gives us strings
that are immutable already, a garbage collector, and a tracing
JIT, all of which are useful.

C can't do one of these without refcounts, can it? It seems like
one of those projects where writing it in C entails writing a
crappy garbage collector.

It's a silly question. Cedar at Mesa had a perfectly usable
garbage-collected rope text editor in the early 80s on a
computer comparable to my TI-89. Unlike a parser, which literally
cannot be fast enough, let alone too fast (if a parser could be fast
enough, it could parse encrypted data, and it cannot), an editor
just has to be faster than fat-fingered wetbrains.

We do want to add a simple double-pointer pivot type from C,
and do pivot assignment across the FFI. It's much smaller and we
use a lot of pivots.

The [[http://luajit.org/ext_ffi.html][LuaJIT FFI]] makes this simple.

Parse repair. That's the actual hard part.

On the other hand, having a pure C library is nice, because then
everyone can use it. Writing anything even slightly complex for the
first time in pure C is a habit I don't have.

There's also no reason the strings have to be strings. The edges
could instead define an entry point into a [[http://cr.yp.to/critbit.html][crit bit]] trie. This
makes the strings themselves immutable, letting us concentrate
on the data structure.

It's funny to contemplate but given a preloaded crit bit dictionary,
adding text will add two additional pointer's worth per unique word or
phrase. Pointers are fat enough that they're most of the weight,
clocking in at sixteen asciis for two.

At that point, what's even left? The strings, nodes, and pivot chains
all inhabit separate spaces encouraging the performances they typically
engage in, and we've spent the minimal amount of memory to obtain
those separate guarantees.

This is approximated by using Lua's immutable strings to hold the leaves.
They're interned into a single data structure that's crit-bit-like.
