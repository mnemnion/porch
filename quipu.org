#+options: H:4
* The Quipu Data Structure

The [[http://en.wikipedia.org/wiki/Rope_%28data_structure%2][rope]] data structure has an interesting quality: it could be implemented
such that the structure of the rope is the same as the structure of the
abstract syntax tree.

The rope itself is efficient and works well for text editing. Combining ropes
with semantics we call a quipu.

** Prerequisites

A good parser. [[https://github.com/UpstandingHackers/hammer][Hammer]] is the leading candidate. A binary focus may be turned
and tuned to utf-8, going the other direction is painful. The parser will
be capable of outputting several data structures, the quipu form among them,
offset tables being the other major flavor.

The parser must have a good [[file:parse-repair.org][parse repair strategy]]. Keeping things tree-like
is critical to performance. Although we can and will fall back on the basic
rope for flat sections, this isn't acceptable for the larger application,
which is a ground-up, semantically-aware library of editing functions.

** Structure

A rope node contains the length and pointers to the left and right.

A quipu adds an enriched node type, that has semantics and is n-ary.

We balance the quipu by inserting additional, ordinary-rope-like
nodes, which we call pivots.

We end up  with a binary tree,  used for editing, braided  with an n-ary
tree, used  for semantic purposes. The  DAG has the properties  of being
well-formed (single root node) and convergent (both the n-ary and binary
DAGs contain the same leaf nodes, reached by different paths).

** Use

Superficially, it works similarly to a rope. But to stay semantically in sync,
it has to cooperate with the parser, and this can be a disaster if not carefully
implemented.

Parsing is an all-or-nothing proposition, normally: a string is correct right up
until it isn't, and then it's all wrong. Even regex scans that approximate a parse,
like syntax highlighting, gets tripped up by this: delete the " at the end of a
string in a code editor to see what I mean. I suspect you already have.

Fortunately for all of us, [[http://www.antlr.org/][ANTLR]] has an incredible parse repair algorithm. I've
mentioned it a few times in notes and really need to crack open the PDF and
transcribe it, because it really impressed me and it can be adapted to PEGs.
The reference is section 9.3 of the manual.

As I said, you need a really good parser. But with that parser, and a quipu,
one can write a really tight editing library on top.

That is a topic for another page.

** Data Structures

The pivots need three slots: left, right, and length. All nodes have to be a pivot,
in a sense, but the paths are distinct, so we can rebalance the tree. Though they are
notably present in zigzag form within the pivots, indeed that is the point.

So rather than using the zeroes for tagging, we'll use them to indicate the length. 64
bit alignment, which will apply to all our pointers, leaves us six free bits. We'll just flip one
if the pointer contains the length.

In fact, let's optimize a bit further. There are a grip of tokens that are just "  {" and maybe
a newline. We need four bits to store an ASCII character. Meaning we can use the second of our bits
to encode a token up to seven characters within the node itself. This is quite friendly to our cache
in comparison.

Oh wait, if it doesn't have a length, it is a length, so let's go further. We can store up to
23 characters inside the same discriminated union.

That's a nice number. The previous sentence fits in that number. Variables tend to fit in that number.
Dictionary words fit in that number.

Hmm. As I think about it, the Nodes need a length too.
Keeping it on the semantic side will absolutely kill us.

This being C, I could proceed by leaving the Node out of the
discriminated union, and casting Node pointers to the union
type for function calls. We place the semantic pointer out
of reach.

But this reminds me of Knuth's full quote:

#+begin_quote
"Programmers waste enormous amounts of  time thinking about, or worrying
about,  the speed  of noncritical  parts  of their  programs, and  these
attempts  at efficiency  actually  have a  strong  negative impact  when
debugging and maintenance  are considered. We should  forget about small
efficiencies, say about  97% of the time: premature  optimization is the
root of all  evil. Yet we should  not pass up our  opportunities in that
critical 3%."
#+end_quote

General data structures are well within that 3% margin. Memory is not
at a premium, cache misses are costly and will remain so.

**** Structure redux

We are writing a fast editor for structured text. "Fast" means it can
reasonably handle a few tens of thousands of lines of text structured
into memory at once. It can 'open' an arbitrarily large file, and
has separate threads (entire Lua workers actually) for user interaction
and any command that needs to be asynced, which is most.

Let's just say that a Quipu cell is four words long. If it's a Pivot,
it's left, right, length, reference pointer (not null, for several reasons).
If it's a Node, left, right, length, and semantic pointer.

This gives us another important property: we can convert a pivot into
a node without copying. With careful layout in initial parsing,
ultimately heuristic, we can leave space to rearrange quipu in a
cache and allocation efficient fashion, while preserving the tree
structure.

The tag block is stored in the least position of the tail pointer. We are
allowed eight different states, for 32 bit compatibility of the library.

We have:

-   0 :: The cell is a Node (semantic)
-   1 ::  The cell is a Pivot
-   2 ::  The cell is a Knot
-   3 ::  The cell is a Strand


#+begin_src plantuml :file quipu-data-structures.png :export none

@startuml
object firstObject
object "My Second Object" as o2
@enduml

#+end_src

=Strand= being a cell with a blank(ish?) left, a right that points to
a sequence longer than 31 byes, and the length of that sequence.

Clearly we can't use a null pointer for the tail pointer, for a Pivot.
We could use an almost-null pointer, but I'd rather define a semantics
for the pointer-after-masking, if there's one which is plausible. If
we accidentally try to jump to a tagged pointer undefined things will
happen as you can't load a frame from unaligned memory. I assume the
kernel will boot your crazy process right out of existence but have
yet to test this.

Candidates would be some kind of mutation chain. write-on-copy
semantics make more sense than copy-on-write, and that implies
using a separate data structure to store revision.

More plausible is ownership references. If quipu start sharing structure,
as is plausible, it could be nice to know which quipu owns a reference
and which one is merely containing it. This would let the system decide
whether an edit in a multiply-linked quipu should trigger a copy or
obey the default semantics of editing both simultaneously.

There's also room for one more type of Pivot, before getting into the
kind of elaborate subclassing that could affect constant factors inside
the hottest of loops. The case of a pivot with a left pointer and
a null-like right pointer remains unexplored.

For a knot, we have 31 chars we  can fit in a token. That's a legal
limit  in some  languages for  tokens such  as variables.  It holds  the
string "antidisestablishmentarianism" which strikes  me as sufficient to
our purposes. One could modify it to "antidisestablishmentarianistic"
without triggering a resplit or strandout.

It's quite possible this will let us use some vector operation on each
quipu node, doing all necessary comparisons as a 128 bit mask. That would
be pretty neat. In particular 128-bit compare for string equality, this
guarantees us a very hot path indeed for token comparisons. O(n) the
number of hairs in the string.

Either way the reference implementation should be simple and easy to understand
and profile.

**** Strands

The Strand struct has an interesting property: the right slot isn't occupied,
and is only semantically empty. The tail flag defines the entire cell as a
Strand.

My intention is to store absolutely all strings in Knots, unless performance
is suffering and I can prove it's libquipu and not the parser or libfemto
or something else.

strand-outs can therefore have a function pointer in the head slot that
provides an API for interpreting the resulting pointer. A strand-out could,
for a very useful case, lead to a syscall that reads more of a file from
store.

Advanced uses of the quipu contemplate working with large amounts of binary
data without converting it to strings. We can JIT display regions of that
data by strandouts and a function pointer interpreting the length and
region pointer to return a relevant string. By handing around the resulting
quipu, we can let applications pretend they've had a serialization /
deserialization cycle.

Strands get added once the core structures and basic operations are built,
tested, and stable.

** Picture

Here's a lisp tree:

#+begin_src emacs-lisp :exports code
  (defun foo (eeny meeny)
      "a foo function"
      if (eq eeny meeny )
      (miney moe)
      (fi fie fo fum))
#+end_src

Let's render the AST:

#+BEGIN_SRC dot :file images/node-leaf.png  :exports results :cache yes
   digraph G {
  list [label = "list", style = filled, fillcolor = cyan]

  node_1 [label = "defun", style = filled, fillcolor = gray]
  foo_node [label = "foo", style = filled, fillcolor = gray]
  list_1 [label = "list 1", style = filled, fillcolor = cyan]
  node_4 [label = "\"a foo function\"", style = filled, fillcolor = gray]
  list_2 [label = "list 2", style = filled, fillcolor = cyan]
  node_5 [label = "if", style = filled, fillcolor = gray]
  list_3 [label = "list 3", style = filled, fillcolor = cyan]
  list_4 [label = "list 4", style = filled, fillcolor = cyan]
  node_2 [label = "eeny", style = filled, fillcolor = gray]
  node_3 [label = "meeny", style = filled, fillcolor = gray]
  list_5 [label = "list 5", style = filled, fillcolor = cyan]
  list_6 [label = "list 5", style = filled, fillcolor = cyan]
  node_6 [label = "eq", style = filled, fillcolor = gray]
  node_7 [label = "eeny", style = filled, fillcolor = gray]
  node_8 [label = "meeny", style = filled, fillcolor = gray]
  node_9 [label = "miney", style = filled, fillcolor = gray]
  node_10 [label = "mo", style = filled, fillcolor = gray]
  node_11 [label = "fi", style = filled, fillcolor = gray]
  node_12 [label = "fie", style = filled, fillcolor = gray]
  node_13 [label = "fo", style = filled, fillcolor = gray]
  node_14 [label = "fum", style = filled, fillcolor = gray]
    list -> node_1
    list -> foo_node
     list -> list_1
     list_1 -> node_2
     list_1 -> node_3
     list -> node_4
     list -> list_2
     list_2 -> node_5
     list_2 -> list_3
     list_3 -> list_4
     list_4 -> node_6
     list_4 -> node_7
     list_4 -> node_8
     list_3 -> list_5
     list_5 -> node_9
     list_5 -> node_10
     list_3 -> list_6
     list_6 -> node_11
     list_6 -> node_12
     list_6 -> node_13
     list_6 -> node_14
  }

#+END_SRC

#+RESULTS[a717a90928e0c199fb262837a042001b8f1059c4]:
[[file:images/node-leaf.png]]

I made it fairly balanced.

Now let's painstakingly add some pivots.


#+begin_src dot :file images/node-pivot-leaf.png  :exports results :cache yes
   digraph G {
  list [label = "list", style = filled, fillcolor = cyan]
  pivot_1 [label = "pivot", style = filled, fillcolor = green]
  node_1 [label = "defun", style = filled, fillcolor = gray]
  foo_node [label = "foo", style = filled, fillcolor = gray]
  pivot_2 [label = "pivot", style = filled, fillcolor = green]
  list_1 [label = "list 1", style = filled, fillcolor = cyan]
  pivot_3 [label = "pivot", style = filled, fillcolor = green]
  node_4 [label = "\"a foo function\"", style = filled, fillcolor = gray]
  list_2 [label = "list 2", style = filled, fillcolor = cyan]
  node_5 [label = "if", style = filled, fillcolor = gray]
  list_3 [label = "list 3", style = filled, fillcolor = cyan]
  list_4 [label = "list 4", style = filled, fillcolor = cyan]
  node_2 [label = "eeny", style = filled, fillcolor = gray]
  node_3 [label = "meeny", style = filled, fillcolor = gray]
  list_5 [label = "list 5", style = filled, fillcolor = cyan]
  list_6 [label = "list 6", style = filled, fillcolor = cyan]
   pivot_5 [label = "pivot", style = filled, fillcolor = green]
  node_6 [label = "eq", style = filled, fillcolor = gray]

  node_7 [label = "eeny", style = filled, fillcolor = gray]
  node_8 [label = "meeny", style = filled, fillcolor = gray]
  node_9 [label = "miney", style = filled, fillcolor = gray]
  node_10 [label = "mo", style = filled, fillcolor = gray]
  pivot_6 [label = "pivot", style = filled, fillcolor = green]
  node_11 [label = "fum", style = filled, fillcolor = gray]
  node_12 [label = "fo", style = filled, fillcolor = gray]
  node_13 [label = "fi", style = filled, fillcolor = gray]
  node_14 [label = "fie", style = filled, fillcolor = gray]
  pivot_7 [label = "pivot", style = filled, fillcolor = green]
  pivot_8 [label = "pivot", style = filled, fillcolor = green]

    list -> pivot_1 [color = red]
    list -> node_1
    list -> foo_node
       pivot_1 -> node_1 [color = red]
       pivot_1 -> foo_node [color = red]
    list -> pivot_2 [color = red]
     pivot_2 -> list_1 [color = red]
     list -> list_1
     list_1 -> node_2  [color = red]
     list_1 -> node_3   [color = red]
     pivot_2 -> pivot_3 [color = red]
     pivot_3 -> node_4  [color = red]
     pivot_3 -> list_2  [color = red]
     list -> node_4
     list -> list_2
     list_2 -> node_5    [color = red]
     list_2 -> list_3   [color = red]
     list_3 -> list_4   [color = red]
     list_4 -> node_6   [color = red]
     list_4 -> node_7
     list_4 -> node_8
     list_4 -> pivot_5   [color = red]
     pivot_5 -> node_7   [color = red]
     pivot_5 -> node_8   [color = red]
     list_3 -> list_5
     list_3 -> pivot_6    [color = red]
     pivot_6 -> list_5    [color = red]
     pivot_6 -> list_6    [color = red]
     list_5 -> node_9    [color = red]
     list_5 -> node_10   [color = red]
     list_3 -> list_6
     list_6 -> node_11
     list_6 -> node_12
     list_6 -> pivot_7      [color = red]
     pivot_7 -> node_11     [color = red]
     pivot_7 -> node_12     [color = red]
     list_6 -> pivot_8      [color = red]
     list_6 -> node_13
     list_6 -> node_14



     pivot_8 -> node_13     [color = red]
     pivot_8 -> node_14     [color = red]
  }
#+end_src

#+RESULTS[e3757a81acd6d8009b3ec5aac1911875fb11a583]:
[[file:images/node-pivot-leaf.png]]

The black lines aren't present below C level, the quipu structure is unaware of
them. Clearly, they may be traveled by following the pivots.

That's a quipu. Parens and whitespace elided, they don't really help.

There are places to make this more balanced, like pivoting between list 4
and 5 instead of 5 and 6.

**** DONE Get dot working with Org
     CLOSED: [2015-03-17 Tue 22:19]
** Properties

One nice property: the syntactics of a Node are present in the quipu
structure. We may determine what sort of Node we have in the same
operation that determines that we have a Node in the first place.

This is critically important, because a typical use case keeps the
Node semantics in a managed environment. Reparses shoudn't need to
touch an FFI, or they'll be slow, and we hate slow.

Nodes created or deleted during a reparse need to be registered
with the environment, but that's okay.

What's more important is that semantic operations can be pushed
down below C level, where they can be fast and stay fast.

Quipu is designed to work with heavily convoluted documents, containing
multiple syntaxes, with the intention of doing complex operations
across the resulting data. Operations such as code folding, which are
conveniences in other languages, are basic to the metalanguage
environment we're empowering.

** Balancing

Ropes like to be binary and balanced. Parse trees are either n-ary and fairly
well balanced, or binary and strongly tail-loaded.

I suspect one could get acceptable balance by forcing a left-right structure onto
n-ary nodes. These pivot nodes would be anonymous so ((foo)(bar)(baz)), which
we'd often parse

- cons
  - head :: "foo""
  - tail :: cons
    - head :: "bar"
    - tail :: cons
      - head :: "baz"

We could instead parse

- list
 - head :: pivot
   - head :: pivot
      - head :: "foo"
      - tail :: ""bar""
   - tail :: pivot
      - head :: "baz"

Leaving out a level of detail to make the picture more clear.

We can see with this small example that it's not growing left. A typical long parse,
intuitively, will end up balanced with this approach. Balanced enough.

Also worth remembering: We're doing semantic editing with this library. It will,
almost by definition, have poorer algorithmic characteristics than a structure-unaware
string of some sort, such as a skip-list rope.

However, we were going to do semantic analysis on that string anyway. Normally this is a
regular expression driven parse over at least the region under display, with periodic
full reparses by the language runtime. We can't normally eliminate the latter, at least
not at first, but the point of a quipu is to perform that semantic analysis and then preserve
it through various transformations, nearly all of which put the parse tree in a temporary
state of error.

We can also rebalance off the pivots, by flipping them on and off in various ways. The pivots
don't affect the semantics of the tree, just the shape, they don't have to be added in
consistent ways, we can attempt to pivot in the balancing direction each time.

*** Digging in


The basic strategy has two types of node.

The initial parse creates semantic nodes, which are n-ary and link
together. Semantic nodes that aren't unary or binary contain an
additional two slots.

The  balance  pass  assigns  a  left-right chain  through  each  of  the
subnodes. The pointers for the first two subnodes go into left and right
respectively and are distributed among the subnodes accordingly.

Since we know the bias of the nodes, which are aware of their span,
we can correct for it with our pivot placement.

We now have a quipu, with nodes, some of which are fat, and pivots, which
give our tree a balanced shape.

We can save these to store by translating the pointers into offsets and compressing the
node structure into a header. This can be laid out in a cache-friendly way,

The tendency of structured data is to stay structured, and our parser will be
designed to enforce this.

Since our pivots are anonymous, we can break any long flat
data up into ordinary ropes.
** Operations

**** Recognition

** Algorithmic Properties.

I believe the quipu inherits the properties of a rope for ordinary operations.
To be fair, it can't be tuned to maintain a fully optimal structure, by choosing
a string length that complements the cache, balancing the tree with only speed
in mind, and so on.

But again, we use a quipu when we were going to have an AST anyway. This
gap-buffer plus a grip of regex nonsense has to stop.

Note that nodes are also pivots, so in a quipu 'node' refers specifically to
the n-ary structure with attached semantics. pivot refers to both.

Let's call *n*  the number of nodes,  *p* the number of  pivots, and *c*
the number of characters in the string. n < p < c, the first a subcategory
of the second.

The rope is known to hang out around gap buffers and skip lists for baseline
performance, with qualities that suit it to immutable edits.

The quipu inherits this, with other interesting properties.

=mark-region= is O(?), where ? is the number of nodes between master and the
region to be highlighted. This is true of any similar functions, such as
code folding or most colorizing. What's the average here?

Operations such as seach-and-replace  or autocomplete become faster when
restricted to semantic categories. We  can completely skip any subregion
that won't have our information.

Consider a literate document, split into presentation and code. From
the perspective of our environment, they may as well be completely
separate: each boundary is visited once and declined immediately.

A common situation is to have a string which is interpolated with other data
along semantic boundaries. The *ML family of markup languages are useful
to work with in this fashion. The object pointer in the node structures
allows us to abstract away this situation, and render it flexibly, with
good performance.

The goal is to combine the time characteristics of a rope and an AST
for their characteristic problem domains, with a modest, O(p-n) increase in memory
requirements over a perfectly flat string indexed by an AST.

We can probably make  it smaller than a rope indexed by  an AST. We also
avoid the inevitable  complexity of applying a  tree-like structure over
another tree-like structure, which may well be discontiguous in memory.

*** Cache Awareness

Though by no means the first thing to add, implementation should proceed with
an eye towards cache-friendly layout.

I could use a lot of help. I know the basics but have in fact never
written code with hard performance requirements like we're talking about here.

I learned the craft on a 286 with 640k OK and have miserly instincts, so
I do care.

I know we want chunks to be large enough that they flow through a pipeline,
but small enough that if we hand them off to garbage collectors they won't get
tagged as enormous and impossible to move.

The basic strategy is to write into blocks allocated from some pool, packing the
pivots into the front and the strings into the back. The strings should have
telomeres on both sides, zeroes we can consume with additions, and should be in
order, so we can strip the strings by pulling off the footers and filtering nulls.

At minimum, front telomeres that make our strings start on a /8 offset will
likely improve our prospects. In some parsed context many strings will be shorter
than 8 bytes.



I haven't the faintest idea how to move the contents around as the quipu are
juggled. BTW the zeroes in the telomeres are junk, not semantics, the quipu
preserves the length of data. It's safe to stuff zeroes in there, as long
as you're willing to strip the data back out using the quipu rather than
footer filtering.

I want this to be fast enough that it would be worth writing a filesystem
over it. That's not what I want it for, but it would make the application
in question better.

** Immutability

It's worthwhile having a version of this that's designed for immutable revision.

My head starts to swell when I have to think about immutable data structures,
especially when thread-safe references are going to be in the picture. Add this to
the cache picture and we're well outside my comfort zone.

I do know that the zipper has much wisdom to provide.

The basic strategy is to add one more pointer to semantic nodes. Any change that affects
a node is recorded as a back reference, and the node affected gets a pointer stuffed
onto a stack. That's your global undo. Regional undo follows the back reference
and must remove that change from the stack.

I'm pretty sure the old state is cloned and put in the past, so that a give node
retains the same literal identity. At least for our purposes. This makes it slow,
but possible, to access old trees. We have revision control for that purpose,
and are more interested in undos than working with the full state of old data.

** Integration

A string library isn't particularly useful on its own. Strings are the
classic case for garbage collection, and we want the quipu to be
usable from dynamic languages.

Lua lets us use [[http://stackoverflow.com/questions/3578401/lua-garbage-collection-userdata][lua_newuserdata()]] in place of malloc(), allowing the GC
to handle reference counting directly. We'll want to make malloc() and
free() into macros, since I'm sure most GC languages with a good FFI
provide an equivalent function.

This is simplistic, there are many questions to answer, but we're past
the point where continuing to specify is practical. Bottom line, it's a
DAG, and DAGs have been allocated and freed before.
* Implementations

Let's begin with C.

** libquipu

*** #include and #define

Tangled into source and header.

#+begin_src C
//| * libquipu
//| #summary Provides core data structure for textual operations.
//| #dependencies @c/standard
//|

#include <stdio.h>
#include <stdint.h>

#define U_KNOT uintptr_t
#define PIVOT_VAL
#define PIVOT_SEM_PTR 93   // arbitrary
#define STRAND_SEM_PTR 42  // likewise
#+end_src

*** Data Structure

Our discriminated union. Tangled into source and header.

**** TODO add masks for least byte

#+begin_src C
//| ** Data structures

union Quipu ;

typedef struct Pivot {
	union Quipu * left  ;
	union Quipu * right ;
	U_KNOT len ;
	U_KNOT  pivot_v ;
} Pivot ;

typedef struct Node {
	union Quipu * left  ;
	union Quipu * right ;
	U_KNOT len ;
	void * sem_ptr ;
} Node ;

typedef struct Hair {
	char * str[31] ;
	char buffer ; // = flag value; 3?

} Hair ;

typedef struct Strand {
	union Quipu * left  ; // initialized w. customary value
	union Quipu * right ;
	U_KNOT len ;
	U_KNOT strand_v ;
} Strand ;

typedef union  Quipu {
    Pivot  pivot   ;
    Node   node    ;
    Hair   hair    ;
    Strand strand  ;
} Quipu ;
#+end_src

That might be as far as I get today.
